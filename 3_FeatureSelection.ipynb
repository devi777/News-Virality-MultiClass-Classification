{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "3_FeatureSelection.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devi777/News-Virality-MultiClass-Classification/blob/master/3_FeatureSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG9NW5lstyAv",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuWtm0dTtyA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-MeYa3etyA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('News3.csv')\n",
        "X = dataset.iloc[:, 1:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC4bliyHtyBJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "f8d552bb-6ea9-4b6c-9a80-1606b01981d0"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NAME</th>\n",
              "      <th>VPM</th>\n",
              "      <th>KOB</th>\n",
              "      <th>DPPV</th>\n",
              "      <th>DTS</th>\n",
              "      <th>BR</th>\n",
              "      <th>TP</th>\n",
              "      <th>TR</th>\n",
              "      <th>PB</th>\n",
              "      <th>PPD</th>\n",
              "      <th>AR</th>\n",
              "      <th>SEM</th>\n",
              "      <th>TFPM</th>\n",
              "      <th>DA</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>YahooNews</td>\n",
              "      <td>175000000</td>\n",
              "      <td>2.800</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.600</td>\n",
              "      <td>39.2</td>\n",
              "      <td>8.3</td>\n",
              "      <td>0.228022</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>395</td>\n",
              "      <td>1.10</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HuffingtonPost</td>\n",
              "      <td>110000000</td>\n",
              "      <td>1.200</td>\n",
              "      <td>1.50</td>\n",
              "      <td>2.260</td>\n",
              "      <td>48.1</td>\n",
              "      <td>20.8</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29</td>\n",
              "      <td>11655</td>\n",
              "      <td>4500</td>\n",
              "      <td>11.40</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CNN</td>\n",
              "      <td>95000000</td>\n",
              "      <td>1.100</td>\n",
              "      <td>2.28</td>\n",
              "      <td>4.230</td>\n",
              "      <td>52.3</td>\n",
              "      <td>29.1</td>\n",
              "      <td>0.659864</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30</td>\n",
              "      <td>72</td>\n",
              "      <td>417</td>\n",
              "      <td>47.20</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NewYorkTimes</td>\n",
              "      <td>70000000</td>\n",
              "      <td>1.700</td>\n",
              "      <td>2.50</td>\n",
              "      <td>3.150</td>\n",
              "      <td>60.6</td>\n",
              "      <td>41.9</td>\n",
              "      <td>0.945824</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>555</td>\n",
              "      <td>44.70</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FoxNews</td>\n",
              "      <td>65000000</td>\n",
              "      <td>0.550</td>\n",
              "      <td>2.59</td>\n",
              "      <td>5.210</td>\n",
              "      <td>46.3</td>\n",
              "      <td>22.2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30</td>\n",
              "      <td>227</td>\n",
              "      <td>15</td>\n",
              "      <td>18.50</td>\n",
              "      <td>95</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NBCNews</td>\n",
              "      <td>63000000</td>\n",
              "      <td>0.460</td>\n",
              "      <td>1.37</td>\n",
              "      <td>2.260</td>\n",
              "      <td>74.3</td>\n",
              "      <td>46.6</td>\n",
              "      <td>1.290859</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30</td>\n",
              "      <td>507</td>\n",
              "      <td>1000</td>\n",
              "      <td>7.50</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MailOnline</td>\n",
              "      <td>53000000</td>\n",
              "      <td>0.710</td>\n",
              "      <td>2.04</td>\n",
              "      <td>4.350</td>\n",
              "      <td>59.1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.631164</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30</td>\n",
              "      <td>271</td>\n",
              "      <td>16</td>\n",
              "      <td>16.40</td>\n",
              "      <td>94</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TheGuardian</td>\n",
              "      <td>42000000</td>\n",
              "      <td>1.400</td>\n",
              "      <td>2.64</td>\n",
              "      <td>2.683</td>\n",
              "      <td>62.7</td>\n",
              "      <td>52.7</td>\n",
              "      <td>1.203196</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30</td>\n",
              "      <td>119</td>\n",
              "      <td>50</td>\n",
              "      <td>8.20</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ABCNews</td>\n",
              "      <td>36000000</td>\n",
              "      <td>0.482</td>\n",
              "      <td>1.39</td>\n",
              "      <td>2.330</td>\n",
              "      <td>70.8</td>\n",
              "      <td>45.2</td>\n",
              "      <td>1.231608</td>\n",
              "      <td>1.0</td>\n",
              "      <td>25</td>\n",
              "      <td>1047</td>\n",
              "      <td>1230</td>\n",
              "      <td>0.05</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TimesOfIndia</td>\n",
              "      <td>212000000</td>\n",
              "      <td>0.063</td>\n",
              "      <td>1.40</td>\n",
              "      <td>2.050</td>\n",
              "      <td>64.1</td>\n",
              "      <td>46.2</td>\n",
              "      <td>0.540351</td>\n",
              "      <td>0.5</td>\n",
              "      <td>26</td>\n",
              "      <td>18024</td>\n",
              "      <td>467</td>\n",
              "      <td>12.70</td>\n",
              "      <td>93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>NDTVNews</td>\n",
              "      <td>50000000</td>\n",
              "      <td>0.610</td>\n",
              "      <td>2.36</td>\n",
              "      <td>3.980</td>\n",
              "      <td>56.5</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.714521</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30</td>\n",
              "      <td>358</td>\n",
              "      <td>11</td>\n",
              "      <td>12.60</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>IndiaToday</td>\n",
              "      <td>17000000</td>\n",
              "      <td>0.300</td>\n",
              "      <td>1.59</td>\n",
              "      <td>2.380</td>\n",
              "      <td>74.6</td>\n",
              "      <td>78.2</td>\n",
              "      <td>1.486692</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>567</td>\n",
              "      <td>70</td>\n",
              "      <td>5.30</td>\n",
              "      <td>89</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>IndianExpress</td>\n",
              "      <td>18000000</td>\n",
              "      <td>0.319</td>\n",
              "      <td>2.34</td>\n",
              "      <td>3.530</td>\n",
              "      <td>62.1</td>\n",
              "      <td>41.3</td>\n",
              "      <td>0.645312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30</td>\n",
              "      <td>1100</td>\n",
              "      <td>7</td>\n",
              "      <td>3.50</td>\n",
              "      <td>91</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>TheHindu</td>\n",
              "      <td>65000000</td>\n",
              "      <td>0.253</td>\n",
              "      <td>1.91</td>\n",
              "      <td>2.750</td>\n",
              "      <td>65.8</td>\n",
              "      <td>64.4</td>\n",
              "      <td>1.047154</td>\n",
              "      <td>0.5</td>\n",
              "      <td>30</td>\n",
              "      <td>977</td>\n",
              "      <td>1</td>\n",
              "      <td>6.00</td>\n",
              "      <td>91</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              NAME        VPM    KOB  DPPV    DTS    BR    TP        TR   PB  \\\n",
              "0        YahooNews  175000000  2.800  4.34  4.600  39.2   8.3  0.228022  1.0   \n",
              "1   HuffingtonPost  110000000  1.200  1.50  2.260  48.1  20.8  0.500000  2.0   \n",
              "2              CNN   95000000  1.100  2.28  4.230  52.3  29.1  0.659864  1.0   \n",
              "3     NewYorkTimes   70000000  1.700  2.50  3.150  60.6  41.9  0.945824  1.0   \n",
              "4          FoxNews   65000000  0.550  2.59  5.210  46.3  22.2  0.500000  2.0   \n",
              "5          NBCNews   63000000  0.460  1.37  2.260  74.3  46.6  1.290859  1.0   \n",
              "6       MailOnline   53000000  0.710  2.04  4.350  59.1  32.0  0.631164  2.0   \n",
              "7      TheGuardian   42000000  1.400  2.64  2.683  62.7  52.7  1.203196  1.0   \n",
              "8         Â ABCNews   36000000  0.482  1.39  2.330  70.8  45.2  1.231608  1.0   \n",
              "9     TimesOfIndia  212000000  0.063  1.40  2.050  64.1  46.2  0.540351  0.5   \n",
              "10        NDTVNews   50000000  0.610  2.36  3.980  56.5  43.3  0.714521  1.0   \n",
              "11      IndiaToday   17000000  0.300  1.59  2.380  74.6  78.2  1.486692  0.0   \n",
              "12   IndianExpress   18000000  0.319  2.34  3.530  62.1  41.3  0.645312  0.0   \n",
              "13        TheHindu   65000000  0.253  1.91  2.750  65.8  64.4  1.047154  0.5   \n",
              "\n",
              "    PPD     AR   SEM   TFPM  DA  TARGET  \n",
              "0    25     11   395   1.10  95       0  \n",
              "1    29  11655  4500  11.40  93       1  \n",
              "2    30     72   417  47.20  95       0  \n",
              "3    28     77   555  44.70  95       0  \n",
              "4    30    227    15  18.50  95       1  \n",
              "5    30    507  1000   7.50  92       1  \n",
              "6    30    271    16  16.40  94       1  \n",
              "7    30    119    50   8.20  95       0  \n",
              "8    25   1047  1230   0.05  93       0  \n",
              "9    26  18024   467  12.70  93       1  \n",
              "10   30    358    11  12.60  92       1  \n",
              "11   30    567    70   5.30  89       2  \n",
              "12   30   1100     7   3.50  91       2  \n",
              "13   30    977     1   6.00  91       2  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO1jFfUwtyBT",
        "colab_type": "text"
      },
      "source": [
        "Since, we are not supposed to fit the models on each category, so we will not one-hot encode y this time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgkE9wEVtyBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 4/13, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv2-s3IjtyBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGKVaMagtyBh",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXW9vdrptyBp",
        "colab_type": "text"
      },
      "source": [
        "Backward elimination: which involves starting with all candidate variables, testing the deletion of each variable using a chosen model fit criterion, deleting the variable (if any) whose loss gives the most statistically insignificant deterioration of the model fit, and repeating this process until no further variables can be deleted without a statistically insignificant loss of fit.\n",
        "\n",
        "So, to select k number of features from a total n no of features , we use feature selection or feature extraction to increase our evaluation speed of model and sometimes to visualize the data as well (k = 2/3 if visualizing). Let's implement feature selection in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD5TEzSBtyBq",
        "colab_type": "text"
      },
      "source": [
        "## Backward elimination with Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4N_PjA2tyBw",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9439a0e-c727-4ca9-a526-b3d7cf43e2cc"
      },
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(solver = 'lbfgs')\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkI3WMlDtyCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statsmodels.regression.linear_model as sm \n",
        "# add a column of ones as integer data type \n",
        "X = np.append(arr = np.ones((14, 1)).astype(int), values = X, axis = 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LILEs89RtyC-",
        "colab_type": "code",
        "colab": {},
        "outputId": "f783bf3b-27d5-4048-8ea0-5db4828e1207"
      },
      "source": [
        "# choose a Significance level usually 0.05, if p>0.05 \n",
        "# for the highest values parameter, remove that value \n",
        "X_opt = np.array(X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\devan\\anaconda3\\envs\\tesnor\\lib\\site-packages\\scipy\\stats\\stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
            "  \"anyway, n=%i\" % int(n))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.975</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.676</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.265</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.410</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:28</td>     <th>  Log-Likelihood:    </th> <td>  10.160</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th> <td>   5.681</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     1</td>      <th>  BIC:               </th> <td>   13.99</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  -29.3455</td> <td>   14.314</td> <td>   -2.050</td> <td> 0.289</td> <td> -211.220</td> <td>  152.529</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td> 9.005e-09</td> <td> 6.59e-09</td> <td>    1.367</td> <td> 0.402</td> <td>-7.47e-08</td> <td> 9.27e-08</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>   -1.8676</td> <td>    1.370</td> <td>   -1.363</td> <td> 0.403</td> <td>  -19.281</td> <td>   15.546</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    3.1113</td> <td>    2.174</td> <td>    1.431</td> <td> 0.388</td> <td>  -24.510</td> <td>   30.733</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>    1.4543</td> <td>    0.884</td> <td>    1.645</td> <td> 0.348</td> <td>   -9.776</td> <td>   12.685</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.2255</td> <td>    0.119</td> <td>    1.891</td> <td> 0.310</td> <td>   -1.290</td> <td>    1.741</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.0758</td> <td>    0.031</td> <td>    2.456</td> <td> 0.246</td> <td>   -0.316</td> <td>    0.468</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -2.0334</td> <td>    1.704</td> <td>   -1.194</td> <td> 0.444</td> <td>  -23.679</td> <td>   19.612</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.2214</td> <td>    0.542</td> <td>    0.408</td> <td> 0.753</td> <td>   -6.671</td> <td>    7.114</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    0.1137</td> <td>    0.106</td> <td>    1.076</td> <td> 0.477</td> <td>   -1.229</td> <td>    1.456</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td> 2.213e-05</td> <td>    0.000</td> <td>    0.199</td> <td> 0.875</td> <td>   -0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>    0.0018</td> <td>    0.001</td> <td>    2.135</td> <td> 0.279</td> <td>   -0.009</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>    0.0046</td> <td>    0.022</td> <td>    0.206</td> <td> 0.870</td> <td>   -0.276</td> <td>    0.285</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>26.044</td> <th>  Durbin-Watson:     </th> <td>   1.993</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  31.464</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-2.404</td> <th>  Prob(JB):          </th> <td>1.47e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 8.551</td> <th>  Cond. No.          </th> <td>1.16e+10</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.16e+10. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.975\n",
              "Model:                            OLS   Adj. R-squared:                  0.676\n",
              "Method:                 Least Squares   F-statistic:                     3.265\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):              0.410\n",
              "Time:                        12:02:28   Log-Likelihood:                 10.160\n",
              "No. Observations:                  14   AIC:                             5.681\n",
              "Df Residuals:                       1   BIC:                             13.99\n",
              "Df Model:                          12                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        -29.3455     14.314     -2.050      0.289    -211.220     152.529\n",
              "x1          9.005e-09   6.59e-09      1.367      0.402   -7.47e-08    9.27e-08\n",
              "x2            -1.8676      1.370     -1.363      0.403     -19.281      15.546\n",
              "x3             3.1113      2.174      1.431      0.388     -24.510      30.733\n",
              "x4             1.4543      0.884      1.645      0.348      -9.776      12.685\n",
              "x5             0.2255      0.119      1.891      0.310      -1.290       1.741\n",
              "x6             0.0758      0.031      2.456      0.246      -0.316       0.468\n",
              "x7            -2.0334      1.704     -1.194      0.444     -23.679      19.612\n",
              "x8             0.2214      0.542      0.408      0.753      -6.671       7.114\n",
              "x9             0.1137      0.106      1.076      0.477      -1.229       1.456\n",
              "x10         2.213e-05      0.000      0.199      0.875      -0.001       0.001\n",
              "x11            0.0018      0.001      2.135      0.279      -0.009       0.013\n",
              "x12            0.0046      0.022      0.206      0.870      -0.276       0.285\n",
              "==============================================================================\n",
              "Omnibus:                       26.044   Durbin-Watson:                   1.993\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.464\n",
              "Skew:                          -2.404   Prob(JB):                     1.47e-07\n",
              "Kurtosis:                       8.551   Cond. No.                     1.16e+10\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 1.16e+10. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjB7UHSctyD1",
        "colab_type": "text"
      },
      "source": [
        "So, now we need to keep removing the feature columns whose p-value is greater than 0.05 (taken by standard convention)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3G3dFT6tyEB",
        "colab_type": "text"
      },
      "source": [
        "But as we can see, there isn't even a single column that has p-value smaller than 0.05. This implies we will keep removing the features and in the end, there will be none left to predict the virality. And yes, that's because of the features and the randomly initialized values of y (target). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfO44bBltyEK",
        "colab_type": "text"
      },
      "source": [
        "But let's still implement it, as our aim at the moment is the successful implementation of Backward Elimination, rather than perfectly fitting the model to the data. So, let's keep removing the features which have the highest p-value, and then stop when they are only 2 features left. Let's do this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq0KTZd7tyEO",
        "colab_type": "code",
        "colab": {},
        "outputId": "f00723f0-fc96-4ed7-a81c-f8dca3b1bfd8"
      },
      "source": [
        "#Removing 10th Feature (87%)\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.918</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.646</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.373</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.173</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:28</td>     <th>  Log-Likelihood:    </th> <td>  1.8424</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th> <td>   18.32</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     3</td>      <th>  BIC:               </th> <td>   25.34</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  -13.4172</td> <td>    7.915</td> <td>   -1.695</td> <td> 0.189</td> <td>  -38.608</td> <td>   11.773</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.7867</td> <td>    1.221</td> <td>   -0.644</td> <td> 0.565</td> <td>   -4.672</td> <td>    3.099</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    1.2134</td> <td>    1.796</td> <td>    0.676</td> <td> 0.548</td> <td>   -4.503</td> <td>    6.930</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    0.6911</td> <td>    0.483</td> <td>    1.432</td> <td> 0.248</td> <td>   -0.845</td> <td>    2.227</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>    0.1111</td> <td>    0.088</td> <td>    1.264</td> <td> 0.296</td> <td>   -0.169</td> <td>    0.391</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0601</td> <td>    0.030</td> <td>    2.014</td> <td> 0.137</td> <td>   -0.035</td> <td>    0.155</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -2.7372</td> <td>    1.325</td> <td>   -2.065</td> <td> 0.131</td> <td>   -6.955</td> <td>    1.480</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.0264</td> <td>    0.534</td> <td>   -0.049</td> <td> 0.964</td> <td>   -1.726</td> <td>    1.673</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0981</td> <td>    0.110</td> <td>    0.894</td> <td> 0.437</td> <td>   -0.251</td> <td>    0.447</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>    0.0009</td> <td>    0.001</td> <td>    1.513</td> <td> 0.227</td> <td>   -0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>   -0.0084</td> <td>    0.021</td> <td>   -0.395</td> <td> 0.719</td> <td>   -0.076</td> <td>    0.059</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.209</td> <th>  Durbin-Watson:     </th> <td>   2.100</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.546</td> <th>  Jarque-Bera (JB):  </th> <td>   0.950</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.564</td> <th>  Prob(JB):          </th> <td>   0.622</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.404</td> <th>  Cond. No.          </th> <td>8.62e+04</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.62e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.918\n",
              "Model:                            OLS   Adj. R-squared:                  0.646\n",
              "Method:                 Least Squares   F-statistic:                     3.373\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):              0.173\n",
              "Time:                        12:02:28   Log-Likelihood:                 1.8424\n",
              "No. Observations:                  14   AIC:                             18.32\n",
              "Df Residuals:                       3   BIC:                             25.34\n",
              "Df Model:                          10                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        -13.4172      7.915     -1.695      0.189     -38.608      11.773\n",
              "x1            -0.7867      1.221     -0.644      0.565      -4.672       3.099\n",
              "x2             1.2134      1.796      0.676      0.548      -4.503       6.930\n",
              "x3             0.6911      0.483      1.432      0.248      -0.845       2.227\n",
              "x4             0.1111      0.088      1.264      0.296      -0.169       0.391\n",
              "x5             0.0601      0.030      2.014      0.137      -0.035       0.155\n",
              "x6            -2.7372      1.325     -2.065      0.131      -6.955       1.480\n",
              "x7            -0.0264      0.534     -0.049      0.964      -1.726       1.673\n",
              "x8             0.0981      0.110      0.894      0.437      -0.251       0.447\n",
              "x9             0.0009      0.001      1.513      0.227      -0.001       0.003\n",
              "x10           -0.0084      0.021     -0.395      0.719      -0.076       0.059\n",
              "==============================================================================\n",
              "Omnibus:                        1.209   Durbin-Watson:                   2.100\n",
              "Prob(Omnibus):                  0.546   Jarque-Bera (JB):                0.950\n",
              "Skew:                          -0.564   Prob(JB):                        0.622\n",
              "Kurtosis:                       2.404   Cond. No.                     8.62e+04\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 8.62e+04. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5h0rjjntyE3",
        "colab_type": "code",
        "colab": {},
        "outputId": "34a3ae90-96d8-4019-b48f-3300919c79fa"
      },
      "source": [
        "#Removing 7th Feature (96%)\n",
        "X_opt = np.array(X[:, [0, 2, 3, 4, 5, 6, 8, 9, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.802</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.357</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.803</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.299</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:28</td>     <th>  Log-Likelihood:    </th> <td> -4.3496</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th> <td>   28.70</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     4</td>      <th>  BIC:               </th> <td>   35.09</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>   -2.6666</td> <td>    8.037</td> <td>   -0.332</td> <td> 0.757</td> <td>  -24.981</td> <td>   19.648</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.7544</td> <td>    1.645</td> <td>   -0.458</td> <td> 0.670</td> <td>   -5.323</td> <td>    3.814</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.2461</td> <td>    2.337</td> <td>    0.105</td> <td> 0.921</td> <td>   -6.243</td> <td>    6.735</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>    0.3059</td> <td>    0.600</td> <td>    0.510</td> <td> 0.637</td> <td>   -1.360</td> <td>    1.972</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0174</td> <td>    0.084</td> <td>   -0.208</td> <td> 0.845</td> <td>   -0.250</td> <td>    0.215</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0172</td> <td>    0.029</td> <td>    0.597</td> <td> 0.583</td> <td>   -0.063</td> <td>    0.097</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>   -0.4897</td> <td>    0.653</td> <td>   -0.750</td> <td> 0.495</td> <td>   -2.303</td> <td>    1.323</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>    0.1206</td> <td>    0.147</td> <td>    0.820</td> <td> 0.458</td> <td>   -0.288</td> <td>    0.529</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0004</td> <td>    0.001</td> <td>    0.488</td> <td> 0.651</td> <td>   -0.002</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   -0.0165</td> <td>    0.028</td> <td>   -0.588</td> <td> 0.588</td> <td>   -0.095</td> <td>    0.062</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.901</td> <th>  Durbin-Watson:     </th> <td>   2.368</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.386</td> <th>  Jarque-Bera (JB):  </th> <td>   1.304</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.532</td> <th>  Prob(JB):          </th> <td>   0.521</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.949</td> <th>  Cond. No.          </th> <td>6.60e+04</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.6e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.802\n",
              "Model:                            OLS   Adj. R-squared:                  0.357\n",
              "Method:                 Least Squares   F-statistic:                     1.803\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):              0.299\n",
              "Time:                        12:02:28   Log-Likelihood:                -4.3496\n",
              "No. Observations:                  14   AIC:                             28.70\n",
              "Df Residuals:                       4   BIC:                             35.09\n",
              "Df Model:                           9                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const         -2.6666      8.037     -0.332      0.757     -24.981      19.648\n",
              "x1            -0.7544      1.645     -0.458      0.670      -5.323       3.814\n",
              "x2             0.2461      2.337      0.105      0.921      -6.243       6.735\n",
              "x3             0.3059      0.600      0.510      0.637      -1.360       1.972\n",
              "x4            -0.0174      0.084     -0.208      0.845      -0.250       0.215\n",
              "x5             0.0172      0.029      0.597      0.583      -0.063       0.097\n",
              "x6            -0.4897      0.653     -0.750      0.495      -2.303       1.323\n",
              "x7             0.1206      0.147      0.820      0.458      -0.288       0.529\n",
              "x8             0.0004      0.001      0.488      0.651      -0.002       0.002\n",
              "x9            -0.0165      0.028     -0.588      0.588      -0.095       0.062\n",
              "==============================================================================\n",
              "Omnibus:                        1.901   Durbin-Watson:                   2.368\n",
              "Prob(Omnibus):                  0.386   Jarque-Bera (JB):                1.304\n",
              "Skew:                          -0.532   Prob(JB):                        0.521\n",
              "Kurtosis:                       1.949   Cond. No.                     6.60e+04\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 6.6e+04. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjTqi6dbtyFP",
        "colab_type": "code",
        "colab": {},
        "outputId": "fbc854ee-2447-4c5b-cd96-3e450665558f"
      },
      "source": [
        "#Removing 2nd Feature (92%)\n",
        "X_opt = np.array(X[:, [0, 2, 4, 5, 6, 8, 9, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.802</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.484</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.526</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.161</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:28</td>     <th>  Log-Likelihood:    </th> <td> -4.3690</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th> <td>   26.74</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     5</td>      <th>  BIC:               </th> <td>   32.49</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>   -1.9664</td> <td>    4.044</td> <td>   -0.486</td> <td> 0.647</td> <td>  -12.362</td> <td>    8.429</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.5848</td> <td>    0.302</td> <td>   -1.937</td> <td> 0.110</td> <td>   -1.361</td> <td>    0.191</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.3256</td> <td>    0.511</td> <td>    0.638</td> <td> 0.552</td> <td>   -0.987</td> <td>    1.638</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0248</td> <td>    0.040</td> <td>   -0.614</td> <td> 0.566</td> <td>   -0.129</td> <td>    0.079</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>    0.0167</td> <td>    0.026</td> <td>    0.656</td> <td> 0.541</td> <td>   -0.049</td> <td>    0.082</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>   -0.5419</td> <td>    0.380</td> <td>   -1.425</td> <td> 0.214</td> <td>   -1.520</td> <td>    0.436</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.1281</td> <td>    0.115</td> <td>    1.112</td> <td> 0.317</td> <td>   -0.168</td> <td>    0.424</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>    0.0003</td> <td>    0.000</td> <td>    0.869</td> <td> 0.425</td> <td>   -0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>   -0.0192</td> <td>    0.012</td> <td>   -1.664</td> <td> 0.157</td> <td>   -0.049</td> <td>    0.010</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.017</td> <th>  Durbin-Watson:     </th> <td>   2.340</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.365</td> <th>  Jarque-Bera (JB):  </th> <td>   1.368</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.554</td> <th>  Prob(JB):          </th> <td>   0.504</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.942</td> <th>  Cond. No.          </th> <td>3.57e+04</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.57e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.802\n",
              "Model:                            OLS   Adj. R-squared:                  0.484\n",
              "Method:                 Least Squares   F-statistic:                     2.526\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):              0.161\n",
              "Time:                        12:02:28   Log-Likelihood:                -4.3690\n",
              "No. Observations:                  14   AIC:                             26.74\n",
              "Df Residuals:                       5   BIC:                             32.49\n",
              "Df Model:                           8                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const         -1.9664      4.044     -0.486      0.647     -12.362       8.429\n",
              "x1            -0.5848      0.302     -1.937      0.110      -1.361       0.191\n",
              "x2             0.3256      0.511      0.638      0.552      -0.987       1.638\n",
              "x3            -0.0248      0.040     -0.614      0.566      -0.129       0.079\n",
              "x4             0.0167      0.026      0.656      0.541      -0.049       0.082\n",
              "x5            -0.5419      0.380     -1.425      0.214      -1.520       0.436\n",
              "x6             0.1281      0.115      1.112      0.317      -0.168       0.424\n",
              "x7             0.0003      0.000      0.869      0.425      -0.001       0.001\n",
              "x8            -0.0192      0.012     -1.664      0.157      -0.049       0.010\n",
              "==============================================================================\n",
              "Omnibus:                        2.017   Durbin-Watson:                   2.340\n",
              "Prob(Omnibus):                  0.365   Jarque-Bera (JB):                1.368\n",
              "Skew:                          -0.554   Prob(JB):                        0.504\n",
              "Kurtosis:                       1.942   Cond. No.                     3.57e+04\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 3.57e+04. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovD5IYOrtyFn",
        "colab_type": "code",
        "colab": {},
        "outputId": "bfca2a2d-9cec-46a0-f693-d68fad150213"
      },
      "source": [
        "#Removing 0th Feature (64%)\n",
        "X_opt = np.array(X[:, [2, 4, 5, 6, 8, 9, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.911</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.792</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   7.675</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>           <td>0.0115</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:29</td>     <th>  Log-Likelihood:    </th>          <td> -4.6924</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   25.38</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th>          <td>   30.50</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.6663</td> <td>    0.234</td> <td>   -2.842</td> <td> 0.030</td> <td>   -1.240</td> <td>   -0.093</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>    0.2030</td> <td>    0.415</td> <td>    0.490</td> <td> 0.642</td> <td>   -0.812</td> <td>    1.218</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th> <td>   -0.0397</td> <td>    0.025</td> <td>   -1.605</td> <td> 0.160</td> <td>   -0.100</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th> <td>    0.0180</td> <td>    0.024</td> <td>    0.761</td> <td> 0.476</td> <td>   -0.040</td> <td>    0.076</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th> <td>   -0.4966</td> <td>    0.345</td> <td>   -1.441</td> <td> 0.200</td> <td>   -1.340</td> <td>    0.346</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th> <td>    0.1048</td> <td>    0.098</td> <td>    1.071</td> <td> 0.325</td> <td>   -0.135</td> <td>    0.344</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th> <td>    0.0002</td> <td>    0.000</td> <td>    0.778</td> <td> 0.466</td> <td>   -0.000</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th> <td>   -0.0182</td> <td>    0.011</td> <td>   -1.716</td> <td> 0.137</td> <td>   -0.044</td> <td>    0.008</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.604</td> <th>  Durbin-Watson:     </th> <td>   2.081</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.448</td> <th>  Jarque-Bera (JB):  </th> <td>   1.116</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.449</td> <th>  Prob(JB):          </th> <td>   0.572</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.949</td> <th>  Cond. No.          </th> <td>4.18e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.18e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.911\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.792\n",
              "Method:                 Least Squares   F-statistic:                              7.675\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                      0.0115\n",
              "Time:                        12:02:29   Log-Likelihood:                         -4.6924\n",
              "No. Observations:                  14   AIC:                                      25.38\n",
              "Df Residuals:                       6   BIC:                                      30.50\n",
              "Df Model:                           8                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.6663      0.234     -2.842      0.030      -1.240      -0.093\n",
              "x2             0.2030      0.415      0.490      0.642      -0.812       1.218\n",
              "x3            -0.0397      0.025     -1.605      0.160      -0.100       0.021\n",
              "x4             0.0180      0.024      0.761      0.476      -0.040       0.076\n",
              "x5            -0.4966      0.345     -1.441      0.200      -1.340       0.346\n",
              "x6             0.1048      0.098      1.071      0.325      -0.135       0.344\n",
              "x7             0.0002      0.000      0.778      0.466      -0.000       0.001\n",
              "x8            -0.0182      0.011     -1.716      0.137      -0.044       0.008\n",
              "==============================================================================\n",
              "Omnibus:                        1.604   Durbin-Watson:                   2.081\n",
              "Prob(Omnibus):                  0.448   Jarque-Bera (JB):                1.116\n",
              "Skew:                          -0.449   Prob(JB):                        0.572\n",
              "Kurtosis:                       1.949   Cond. No.                     4.18e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 4.18e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdjWAukgtyGK",
        "colab_type": "text"
      },
      "source": [
        "Okay, 1st feature has p-value 3%. Good going. And our R-squared and adj. R-squared has also improved. Good going."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFA-fyGFtyGN",
        "colab_type": "code",
        "colab": {},
        "outputId": "526fe88a-84d8-44c2-c628-5f64ea7a9724"
      },
      "source": [
        "#Removing 1st Feature (64.2%)\n",
        "X_opt = np.array(X[:, [2, 5, 6, 8, 9, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.907</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.815</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   9.801</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>           <td>0.00373</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:39</td>     <th>  Log-Likelihood:    </th>          <td> -4.9666</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   23.93</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     7</td>      <th>  BIC:               </th>          <td>   28.41</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.6481</td> <td>    0.219</td> <td>   -2.965</td> <td> 0.021</td> <td>   -1.165</td> <td>   -0.131</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>   -0.0436</td> <td>    0.022</td> <td>   -1.973</td> <td> 0.089</td> <td>   -0.096</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th> <td>    0.0105</td> <td>    0.017</td> <td>    0.617</td> <td> 0.557</td> <td>   -0.030</td> <td>    0.051</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th> <td>   -0.4566</td> <td>    0.316</td> <td>   -1.445</td> <td> 0.192</td> <td>   -1.204</td> <td>    0.291</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th> <td>    0.1474</td> <td>    0.042</td> <td>    3.468</td> <td> 0.010</td> <td>    0.047</td> <td>    0.248</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th> <td>  9.74e-05</td> <td>    0.000</td> <td>    0.743</td> <td> 0.481</td> <td>   -0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th> <td>   -0.0186</td> <td>    0.010</td> <td>   -1.866</td> <td> 0.104</td> <td>   -0.042</td> <td>    0.005</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.254</td> <th>  Durbin-Watson:     </th> <td>   2.151</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.534</td> <th>  Jarque-Bera (JB):  </th> <td>   1.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.571</td> <th>  Prob(JB):          </th> <td>   0.605</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.354</td> <th>  Cond. No.          </th> <td>3.20e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.2e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.907\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.815\n",
              "Method:                 Least Squares   F-statistic:                              9.801\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                     0.00373\n",
              "Time:                        12:02:39   Log-Likelihood:                         -4.9666\n",
              "No. Observations:                  14   AIC:                                      23.93\n",
              "Df Residuals:                       7   BIC:                                      28.41\n",
              "Df Model:                           7                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.6481      0.219     -2.965      0.021      -1.165      -0.131\n",
              "x2            -0.0436      0.022     -1.973      0.089      -0.096       0.009\n",
              "x3             0.0105      0.017      0.617      0.557      -0.030       0.051\n",
              "x4            -0.4566      0.316     -1.445      0.192      -1.204       0.291\n",
              "x5             0.1474      0.042      3.468      0.010       0.047       0.248\n",
              "x6           9.74e-05      0.000      0.743      0.481      -0.000       0.000\n",
              "x7            -0.0186      0.010     -1.866      0.104      -0.042       0.005\n",
              "==============================================================================\n",
              "Omnibus:                        1.254   Durbin-Watson:                   2.151\n",
              "Prob(Omnibus):                  0.534   Jarque-Bera (JB):                1.005\n",
              "Skew:                          -0.571   Prob(JB):                        0.605\n",
              "Kurtosis:                       2.354   Cond. No.                     3.20e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 3.2e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue8xdgcjtyGo",
        "colab_type": "text"
      },
      "source": [
        "And now we have another feature (5th). Awesome. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyQy8AEftyGq",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d2379d2-8a90-450e-d5af-ce82dba55fbb"
      },
      "source": [
        "#Removing 3rd Feature (55.7%)\n",
        "X_opt = np.array(X[:, [2, 5, 8, 9, 11, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.902</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.829</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   12.33</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>           <td>0.00116</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:44</td>     <th>  Log-Likelihood:    </th>          <td> -5.3370</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   22.67</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th>          <td>   26.51</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.6958</td> <td>    0.196</td> <td>   -3.544</td> <td> 0.008</td> <td>   -1.149</td> <td>   -0.243</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>   -0.0346</td> <td>    0.016</td> <td>   -2.167</td> <td> 0.062</td> <td>   -0.071</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th> <td>   -0.5511</td> <td>    0.265</td> <td>   -2.076</td> <td> 0.072</td> <td>   -1.163</td> <td>    0.061</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th> <td>    0.1486</td> <td>    0.041</td> <td>    3.646</td> <td> 0.007</td> <td>    0.055</td> <td>    0.243</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th> <td> 8.632e-05</td> <td>    0.000</td> <td>    0.693</td> <td> 0.508</td> <td>   -0.000</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th> <td>   -0.0185</td> <td>    0.010</td> <td>   -1.932</td> <td> 0.089</td> <td>   -0.041</td> <td>    0.004</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.329</td> <th>  Durbin-Watson:     </th> <td>   2.254</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.515</td> <th>  Jarque-Bera (JB):  </th> <td>   0.843</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.216</td> <th>  Prob(JB):          </th> <td>   0.656</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.878</td> <th>  Cond. No.          </th> <td>2.77e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.77e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.902\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.829\n",
              "Method:                 Least Squares   F-statistic:                              12.33\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                     0.00116\n",
              "Time:                        12:02:44   Log-Likelihood:                         -5.3370\n",
              "No. Observations:                  14   AIC:                                      22.67\n",
              "Df Residuals:                       8   BIC:                                      26.51\n",
              "Df Model:                           6                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.6958      0.196     -3.544      0.008      -1.149      -0.243\n",
              "x2            -0.0346      0.016     -2.167      0.062      -0.071       0.002\n",
              "x3            -0.5511      0.265     -2.076      0.072      -1.163       0.061\n",
              "x4             0.1486      0.041      3.646      0.007       0.055       0.243\n",
              "x5          8.632e-05      0.000      0.693      0.508      -0.000       0.000\n",
              "x6            -0.0185      0.010     -1.932      0.089      -0.041       0.004\n",
              "==============================================================================\n",
              "Omnibus:                        1.329   Durbin-Watson:                   2.254\n",
              "Prob(Omnibus):                  0.515   Jarque-Bera (JB):                0.843\n",
              "Skew:                          -0.216   Prob(JB):                        0.656\n",
              "Kurtosis:                       1.878   Cond. No.                     2.77e+03\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 2.77e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFPmU7v1tyG7",
        "colab_type": "code",
        "colab": {},
        "outputId": "668fbda9-78d5-4531-b832-092fb5692f00"
      },
      "source": [
        "#Removing 5th Feature (55.7%)\n",
        "X_opt = np.array(X[:, [2, 5, 8, 9, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.897</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.839</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   15.60</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>0.000334</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:02:45</td>     <th>  Log-Likelihood:    </th>          <td> -5.7446</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   21.49</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     9</td>      <th>  BIC:               </th>          <td>   24.68</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.6799</td> <td>    0.189</td> <td>   -3.592</td> <td> 0.006</td> <td>   -1.108</td> <td>   -0.252</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>   -0.0330</td> <td>    0.015</td> <td>   -2.150</td> <td> 0.060</td> <td>   -0.068</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th> <td>   -0.4688</td> <td>    0.230</td> <td>   -2.035</td> <td> 0.072</td> <td>   -0.990</td> <td>    0.052</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th> <td>    0.1441</td> <td>    0.039</td> <td>    3.689</td> <td> 0.005</td> <td>    0.056</td> <td>    0.233</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th> <td>   -0.0194</td> <td>    0.009</td> <td>   -2.105</td> <td> 0.065</td> <td>   -0.040</td> <td>    0.001</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.735</td> <th>  Durbin-Watson:     </th> <td>   2.334</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.420</td> <th>  Jarque-Bera (JB):  </th> <td>   1.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.310</td> <th>  Prob(JB):          </th> <td>   0.603</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.838</td> <th>  Cond. No.          </th> <td>    131.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.897\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.839\n",
              "Method:                 Least Squares   F-statistic:                              15.60\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                    0.000334\n",
              "Time:                        12:02:45   Log-Likelihood:                         -5.7446\n",
              "No. Observations:                  14   AIC:                                      21.49\n",
              "Df Residuals:                       9   BIC:                                      24.68\n",
              "Df Model:                           5                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.6799      0.189     -3.592      0.006      -1.108      -0.252\n",
              "x2            -0.0330      0.015     -2.150      0.060      -0.068       0.002\n",
              "x3            -0.4688      0.230     -2.035      0.072      -0.990       0.052\n",
              "x4             0.1441      0.039      3.689      0.005       0.056       0.233\n",
              "x5            -0.0194      0.009     -2.105      0.065      -0.040       0.001\n",
              "==============================================================================\n",
              "Omnibus:                        1.735   Durbin-Watson:                   2.334\n",
              "Prob(Omnibus):                  0.420   Jarque-Bera (JB):                1.011\n",
              "Skew:                          -0.310   Prob(JB):                        0.603\n",
              "Kurtosis:                       1.838   Cond. No.                         131.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fEk-YLLtyHZ",
        "colab_type": "text"
      },
      "source": [
        "So, we have all the values almost less than 5%. And, it might occur that the feature with 6% is also importance. So, let's try fitting this one to Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0cO2CYityHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaDzsfFPtyH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_0TB74ztyJU",
        "colab_type": "code",
        "colab": {},
        "outputId": "53b8a63a-01ab-4147-e7cd-58f37ea2a810"
      },
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(solver = 'lbfgs')\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTcr_rNDtyJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VgbqD6pstyJu",
        "colab_type": "code",
        "colab": {},
        "outputId": "2e574334-6516-444a-f933-9c2e33448c47"
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0]\n",
            " [0 2 0]\n",
            " [0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pnA87QRtyLC",
        "colab_type": "code",
        "colab": {},
        "outputId": "5e520492-be0a-42b3-ea6c-9f9be3c07e9f"
      },
      "source": [
        "print('Test accuracy {:.2f}%'.format(classifier.score(X_test,y_test)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 75.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHufU29ZtyLE",
        "colab_type": "text"
      },
      "source": [
        "Nice. Let's now strictly stay with the 5% rule and remove the feautres as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uwSRMfPtyLE",
        "colab_type": "code",
        "colab": {},
        "outputId": "0fad2ec3-afbc-45b7-db41-fcaa7aaf5617"
      },
      "source": [
        "#Removing 3rd Feature (7.2%)\n",
        "X_opt = np.array(X[:, [2, 5, 9, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\devan\\anaconda3\\envs\\tesnor\\lib\\site-packages\\scipy\\stats\\stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=14\n",
            "  \"anyway, n=%i\" % int(n))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.849</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.788</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   14.05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>0.000413</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:03:20</td>     <th>  Log-Likelihood:    </th>          <td> -8.3946</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   24.79</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    10</td>      <th>  BIC:               </th>          <td>   27.35</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.7060</td> <td>    0.216</td> <td>   -3.261</td> <td> 0.009</td> <td>   -1.188</td> <td>   -0.224</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>   -0.0191</td> <td>    0.016</td> <td>   -1.213</td> <td> 0.253</td> <td>   -0.054</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th> <td>    0.1005</td> <td>    0.037</td> <td>    2.684</td> <td> 0.023</td> <td>    0.017</td> <td>    0.184</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th> <td>   -0.0205</td> <td>    0.011</td> <td>   -1.949</td> <td> 0.080</td> <td>   -0.044</td> <td>    0.003</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 0.294</td> <th>  Durbin-Watson:     </th> <td>   1.260</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.863</td> <th>  Jarque-Bera (JB):  </th> <td>   0.446</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.091</td> <th>  Prob(JB):          </th> <td>   0.800</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.144</td> <th>  Cond. No.          </th> <td>    107.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.849\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.788\n",
              "Method:                 Least Squares   F-statistic:                              14.05\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                    0.000413\n",
              "Time:                        12:03:20   Log-Likelihood:                         -8.3946\n",
              "No. Observations:                  14   AIC:                                      24.79\n",
              "Df Residuals:                      10   BIC:                                      27.35\n",
              "Df Model:                           4                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.7060      0.216     -3.261      0.009      -1.188      -0.224\n",
              "x2            -0.0191      0.016     -1.213      0.253      -0.054       0.016\n",
              "x3             0.1005      0.037      2.684      0.023       0.017       0.184\n",
              "x4            -0.0205      0.011     -1.949      0.080      -0.044       0.003\n",
              "==============================================================================\n",
              "Omnibus:                        0.294   Durbin-Watson:                   1.260\n",
              "Prob(Omnibus):                  0.863   Jarque-Bera (JB):                0.446\n",
              "Skew:                          -0.091   Prob(JB):                        0.800\n",
              "Kurtosis:                       2.144   Cond. No.                         107.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW5hFqVntyLG",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d9b627a-6ea8-43fd-f802-b09ff4ebebe5"
      },
      "source": [
        "#Removing 2nd Feature (25.3%)\n",
        "X_opt = np.array(X[:, [2, 9, 12]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.827</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.779</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   17.49</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>0.000170</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:03:21</td>     <th>  Log-Likelihood:    </th>          <td> -9.3554</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   24.71</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    11</td>      <th>  BIC:               </th>          <td>   26.63</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.5920</td> <td>    0.199</td> <td>   -2.972</td> <td> 0.013</td> <td>   -1.030</td> <td>   -0.154</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>    0.0562</td> <td>    0.008</td> <td>    6.642</td> <td> 0.000</td> <td>    0.038</td> <td>    0.075</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th> <td>   -0.0176</td> <td>    0.010</td> <td>   -1.681</td> <td> 0.121</td> <td>   -0.041</td> <td>    0.005</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 2.633</td> <th>  Durbin-Watson:     </th> <td>   0.855</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.268</td> <th>  Jarque-Bera (JB):  </th> <td>   1.283</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.741</td> <th>  Prob(JB):          </th> <td>   0.526</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 3.061</td> <th>  Cond. No.          </th> <td>    45.9</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.827\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.779\n",
              "Method:                 Least Squares   F-statistic:                              17.49\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                    0.000170\n",
              "Time:                        12:03:21   Log-Likelihood:                         -9.3554\n",
              "No. Observations:                  14   AIC:                                      24.71\n",
              "Df Residuals:                      11   BIC:                                      26.63\n",
              "Df Model:                           3                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.5920      0.199     -2.972      0.013      -1.030      -0.154\n",
              "x2             0.0562      0.008      6.642      0.000       0.038       0.075\n",
              "x3            -0.0176      0.010     -1.681      0.121      -0.041       0.005\n",
              "==============================================================================\n",
              "Omnibus:                        2.633   Durbin-Watson:                   0.855\n",
              "Prob(Omnibus):                  0.268   Jarque-Bera (JB):                1.283\n",
              "Skew:                          -0.741   Prob(JB):                        0.526\n",
              "Kurtosis:                       3.061   Cond. No.                         45.9\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_psJFU38tyLK",
        "colab_type": "code",
        "colab": {},
        "outputId": "7480a43f-9e17-4435-df89-2c71cbb38a1a"
      },
      "source": [
        "#Removing 3rd Feature (12.1%)\n",
        "X_opt = np.array(X[:, [2, 9]], dtype=float)\n",
        "classifier_ols = sm.OLS(endog = y, exog = X_opt).fit() \n",
        "classifier_ols.summary() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.782</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.746</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   21.55</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 28 Apr 2020</td> <th>  Prob (F-statistic):</th>          <td>0.000107</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>12:03:21</td>     <th>  Log-Likelihood:    </th>          <td> -10.955</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>    14</td>      <th>  AIC:               </th>          <td>   25.91</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>    12</td>      <th>  BIC:               </th>          <td>   27.19</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th> <td>   -0.6611</td> <td>    0.209</td> <td>   -3.160</td> <td> 0.008</td> <td>   -1.117</td> <td>   -0.205</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th> <td>    0.0496</td> <td>    0.008</td> <td>    6.167</td> <td> 0.000</td> <td>    0.032</td> <td>    0.067</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 1.157</td> <th>  Durbin-Watson:     </th> <td>   0.802</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.561</td> <th>  Jarque-Bera (JB):  </th> <td>   0.737</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.021</td> <th>  Prob(JB):          </th> <td>   0.692</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 1.877</td> <th>  Cond. No.          </th> <td>    39.5</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                                 OLS Regression Results                                \n",
              "=======================================================================================\n",
              "Dep. Variable:                      y   R-squared (uncentered):                   0.782\n",
              "Model:                            OLS   Adj. R-squared (uncentered):              0.746\n",
              "Method:                 Least Squares   F-statistic:                              21.55\n",
              "Date:                Tue, 28 Apr 2020   Prob (F-statistic):                    0.000107\n",
              "Time:                        12:03:21   Log-Likelihood:                         -10.955\n",
              "No. Observations:                  14   AIC:                                      25.91\n",
              "Df Residuals:                      12   BIC:                                      27.19\n",
              "Df Model:                           2                                                  \n",
              "Covariance Type:            nonrobust                                                  \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "x1            -0.6611      0.209     -3.160      0.008      -1.117      -0.205\n",
              "x2             0.0496      0.008      6.167      0.000       0.032       0.067\n",
              "==============================================================================\n",
              "Omnibus:                        1.157   Durbin-Watson:                   0.802\n",
              "Prob(Omnibus):                  0.561   Jarque-Bera (JB):                0.737\n",
              "Skew:                          -0.021   Prob(JB):                        0.692\n",
              "Kurtosis:                       1.877   Cond. No.                         39.5\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twzZi_SPtyLN",
        "colab_type": "text"
      },
      "source": [
        "That's it. Let's fit again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL1VtJ-gtyLO",
        "colab_type": "code",
        "colab": {},
        "outputId": "d4ae6bf1-cef1-4667-87c2-7563d6a93e28"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(solver = 'lbfgs')\n",
        "classifier.fit(X_train, y_train)\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
        "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
        "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
        "                   warm_start=False)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "print('Test accuracy {:.2f}%'.format(classifier.score(X_test,y_test)*100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0]\n",
            " [0 2 0]\n",
            " [0 1 0]]\n",
            "Test accuracy 50.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbQGl3a-tyLQ",
        "colab_type": "text"
      },
      "source": [
        "# Data Visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1m-2Mq4tyLQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "7397256a-cc55-4ed1-b609-90bae8ab4305"
      },
      "source": [
        "# Visualising the Test set results\n",
        "from matplotlib.colors import ListedColormap\n",
        "X_set, y_set = X_test, y_test\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
        "             alpha = 0.75, cmap = ListedColormap(('red', 'green','blue')))\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "                c = ListedColormap(('red', 'green','blue'))(i), label = j)\n",
        "plt.title('Logistic Regression (Test set)')\n",
        "plt.xlabel('BE1')\n",
        "plt.ylabel('BE2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxGSXssGtyLS",
        "colab_type": "text"
      },
      "source": [
        "Yep, removing the other features was a bad idea. But, the advantage of keeping only 2 features is that we can visualize the results of our model predictions. So, we successfully implemented Backward Elimination on our dataset, with a performance of 75%. And that marks the end of the notebook.\n",
        "\n",
        "In the next, we will apply different types of classification models to our dataset, and see which model is a good predictor of the virality of the news/info websites."
      ]
    }
  ]
}